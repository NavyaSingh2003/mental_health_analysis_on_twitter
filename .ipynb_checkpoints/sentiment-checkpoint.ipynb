{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JArof1WZCrHV",
    "outputId": "2f063dec-9a06-409d-d959-01c37a86b7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8rvo8D1TC492"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-2d4_kX0C7jf"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/output_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r40bjsHLDaD1",
    "outputId": "a3c00275-bf72-490c-e5f6-38b6af1aa3f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('like', 988), ('depression', 881), ('one', 703), ('get', 607), ('love', 593), ('know', 581), ('people', 574), ('amp', 561), ('user', 499), ('good', 456)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming 'post_text' is the name of the column containing the text\n",
    "combined_text = ' '.join(df['post_text'].dropna())\n",
    "\n",
    "# Tokenization and Stopword Removal\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "words = word_tokenize(combined_text)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "\n",
    "# Counting Word Frequencies\n",
    "word_counts = Counter(filtered_words)\n",
    "top_10_words = word_counts.most_common(13)\n",
    "\n",
    "\n",
    "# Filter out specific words\n",
    "exclude_words = ['https', 'rt', 'http']\n",
    "\n",
    "# Filter top_10_words list\n",
    "filtered_top_words = [(word, count) for word, count in top_10_words if word.lower() not in exclude_words]\n",
    "\n",
    "\n",
    "# Displaying the Results\n",
    "print(filtered_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_Q7Q5VYExOT",
    "outputId": "325f7db3-44c1-4156-9ce5-41077b2478a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            post_text    emotion\n",
      "0   It's just over 2 years since I was diagnosed w...   surprise\n",
      "1   It's Sunday, I need a break, so I'm planning t...   surprise\n",
      "2   Awake but tired. I need to sleep but my brain ...    sadness\n",
      "3   RT @SewHQ: #Retro bears make perfect gifts and...  happiness\n",
      "4   Itâ€™s hard to say whether packing lists are mak...  happiness\n",
      "5   Making packing lists is my new hobby... #movin...   surprise\n",
      "6   At what point does keeping stuff for nostalgic...   surprise\n",
      "7   Currently in the finding-boxes-of-random-shit ...   surprise\n",
      "8   Can't be bothered to cook, take away on the wa...  happiness\n",
      "9   RT @itventsnews: ITV releases promo video for ...   surprise\n",
      "10  ... also, I have too much stuff. Way, way too ...   surprise\n",
      "11  I never want to put one of these together agai...    sadness\n",
      "12  Moving stuff is bloominâ€™ knackering... and the...   surprise\n",
      "13  Back at the house, moving stuff. Itâ€™s so peace...  happiness\n",
      "14  Urgh. Anxiety. FFS where does it come from?! (...    sadness\n",
      "15  I have too much stuff. Way, way too much... Ma...   surprise\n",
      "16  Hideous traffic on the A14. Must remember to p...    sadness\n",
      "17                Packing and purging. Feels good ðŸ˜ŠðŸ‘ðŸ¼  happiness\n",
      "18  In B&amp;Q looking at internal doors. Fun times ðŸ˜‰  happiness\n",
      "19  Time to get up. So many things to do, such a b...   surprise\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Assuming 'post_text' is the name of the column containing the text\n",
    "tweets_subset = df['post_text'].dropna().iloc[:20]\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to map sentiment scores to emotions\n",
    "def map_to_emotion(score):\n",
    "    if score >= 0.05:\n",
    "        return 'happiness'\n",
    "    elif score <= -0.05:\n",
    "        return 'sadness'\n",
    "    elif score >= 0.0:\n",
    "        return 'surprise'\n",
    "    elif score <= 0.0:\n",
    "        return 'disgust'\n",
    "    elif score > -0.05:\n",
    "        return 'anger'\n",
    "    elif score < 0.05:\n",
    "        return 'fear'\n",
    "\n",
    "# Classify emotions for each tweet in the subset\n",
    "emotions_subset = [map_to_emotion(sia.polarity_scores(tweet)['compound']) for tweet in tweets_subset]\n",
    "\n",
    "# Add the 'emotion' column to the subset DataFrame\n",
    "df.loc[tweets_subset.index, 'emotion'] = emotions_subset\n",
    "\n",
    "# Display the results for the first 20 rows\n",
    "print(df[['post_text', 'emotion']].head(20))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
