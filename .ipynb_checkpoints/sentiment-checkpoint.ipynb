{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JArof1WZCrHV",
    "outputId": "2f063dec-9a06-409d-d959-01c37a86b7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8rvo8D1TC492"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-2d4_kX0C7jf"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/output_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r40bjsHLDaD1",
    "outputId": "a3c00275-bf72-490c-e5f6-38b6af1aa3f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('like', 988), ('depression', 881), ('one', 703), ('get', 607), ('love', 593), ('know', 581), ('people', 574), ('amp', 561), ('user', 499), ('good', 456)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming 'post_text' is the name of the column containing the text\n",
    "combined_text = ' '.join(df['post_text'].dropna())\n",
    "\n",
    "# Tokenization and Stopword Removal\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "words = word_tokenize(combined_text)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "\n",
    "# Counting Word Frequencies\n",
    "word_counts = Counter(filtered_words)\n",
    "top_10_words = word_counts.most_common(13)\n",
    "\n",
    "\n",
    "# Filter out specific words\n",
    "exclude_words = ['https', 'rt', 'http']\n",
    "\n",
    "# Filter top_10_words list\n",
    "filtered_top_words = [(word, count) for word, count in top_10_words if word.lower() not in exclude_words]\n",
    "\n",
    "\n",
    "# Displaying the Results\n",
    "print(filtered_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_Q7Q5VYExOT",
    "outputId": "325f7db3-44c1-4156-9ce5-41077b2478a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            post_text    emotion\n",
      "0   It's just over 2 years since I was diagnosed w...   surprise\n",
      "1   It's Sunday, I need a break, so I'm planning t...   surprise\n",
      "2   Awake but tired. I need to sleep but my brain ...    sadness\n",
      "3   RT @SewHQ: #Retro bears make perfect gifts and...  happiness\n",
      "4   It’s hard to say whether packing lists are mak...  happiness\n",
      "5   Making packing lists is my new hobby... #movin...   surprise\n",
      "6   At what point does keeping stuff for nostalgic...   surprise\n",
      "7   Currently in the finding-boxes-of-random-shit ...   surprise\n",
      "8   Can't be bothered to cook, take away on the wa...  happiness\n",
      "9   RT @itventsnews: ITV releases promo video for ...   surprise\n",
      "10  ... also, I have too much stuff. Way, way too ...   surprise\n",
      "11  I never want to put one of these together agai...    sadness\n",
      "12  Moving stuff is bloomin’ knackering... and the...   surprise\n",
      "13  Back at the house, moving stuff. It’s so peace...  happiness\n",
      "14  Urgh. Anxiety. FFS where does it come from?! (...    sadness\n",
      "15  I have too much stuff. Way, way too much... Ma...   surprise\n",
      "16  Hideous traffic on the A14. Must remember to p...    sadness\n",
      "17                Packing and purging. Feels good 😊👍🏼  happiness\n",
      "18  In B&amp;Q looking at internal doors. Fun times 😉  happiness\n",
      "19  Time to get up. So many things to do, such a b...   surprise\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Assuming 'post_text' is the name of the column containing the text\n",
    "tweets_subset = df['post_text'].dropna().iloc[:20]\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to map sentiment scores to emotions\n",
    "def map_to_emotion(score):\n",
    "    if score >= 0.05:\n",
    "        return 'happiness'\n",
    "    elif score <= -0.05:\n",
    "        return 'sadness'\n",
    "    elif score >= 0.0:\n",
    "        return 'surprise'\n",
    "    elif score <= 0.0:\n",
    "        return 'disgust'\n",
    "    elif score > -0.05:\n",
    "        return 'anger'\n",
    "    elif score < 0.05:\n",
    "        return 'fear'\n",
    "\n",
    "# Classify emotions for each tweet in the subset\n",
    "emotions_subset = [map_to_emotion(sia.polarity_scores(tweet)['compound']) for tweet in tweets_subset]\n",
    "\n",
    "# Add the 'emotion' column to the subset DataFrame\n",
    "df.loc[tweets_subset.index, 'emotion'] = emotions_subset\n",
    "\n",
    "# Display the results for the first 20 rows\n",
    "print(df[['post_text', 'emotion']].head(20))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
